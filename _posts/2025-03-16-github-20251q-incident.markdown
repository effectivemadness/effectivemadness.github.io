---
title:  "2025 1분기 Github Incident 정리"
date:   2025-03-16 23:21:11+0900
categories: [trivia]
tags: [tech, github, incident]
---
개발자라면 쓸 수 밖에 없는 서비스가 몇 있는데요, 스택이나 관심사마다 갑론을박이 있을 수 있지만 그 중에서도 빠지지 않을 서비스라면 Github이 있습니다. 공개 프로젝트를 찾아보기도 하고, 직접 메인테이너로 활동할 수도 있고, 개인적인 블로그 운영을 할 수도 있고, 회사에서도 사용하기도 하는 서비스라 IT 관련된 섹터에서는 피하기 어려운 서비스인데요.

저도 개인 블로그를 Github 에서 호스팅하고 있기도 하고, 회사에서도 Github Enterprise를 사용하고 있어 평일 주말 할 것 없이 접속을 합니다. 그래서 서비스가 장애가 날 때 더 민감하게 반응할 수 밖에 없는데요, 2025년 들어 발생한 장애를 찾아보고 왜 발생했는지 **남의 집 불구경**을 해 보도록 하겠습니다.

시간은 KST기준입니다.

## 1월

### 1월 09일

오전 10시 반경부터 11시경 까지 30분동안 웹훅, 액션, 이슈, PR, Git 서비스, Pages, Codespace 서비스를 접할 때 유저가 500에러를 겪었습니다. 이쯤되면 되는 서비스가 없다고 할 만큼 광범위한 서비스에 장애가 발생한 건데요, **신규 배포에 섞여있던 쿼리 중 Primary DB를 포화되는 쿼리가 원인**이었다고 합니다. Update 요청 중 평균 6%, 피크 6.85%로 에러가 발생했다고 합니다. 장애는 **원인 쿼리를 찾고 해당 배포를 롤백하여 해결**하였습니다.

추후 서비스 배포 시 문제가 될 만한 쿼리를 미리 찾을 수 있도록, 배포가 되더라도 빠르게 감지할 수 있도록 하는 방법을 검토 예정이라 합니다.

https://www.githubstatus.com/incidents/plgzz71xn6zq

### 1월 13일

오전 8시 반경부터 오전 9시 반경까지 1시간동안 Git서비스에 장애가 발생했습니다. 보통 CLI에서 git clone, push, pull 등을 사용할 때 이 서비스를 찌르게 되는데요. 이 기간동안은 관련 기능을 사용할 수 없었습니다. **내부 로드밸런서의 설정 변경**이 있었는데, Git이 의존하는 서비스들의 요청을 Drop하게 되어 장애가 발생했습니다. **설정 변경사항을 롤백해 장애를 해결**하였습니다.

추후 모니터링 및 배포 방식을 개선 해 앞으로 있을 장애 상황 감지 시간 단축 및 자동화된 해결을 할 수 있도록 검토 예정이라 합니다.

https://www.githubstatus.com/incidents/qd96yfgvmcf9

### 1월 30일

 오후 11시 20분경부터 11시 50분경까지 30분동안 Github.com 내 PR와 Issue 등 사이트 전체적인 요청의 최대 44%에 에러가 발생했습니다. 성공하는 요청들은 평균적으로 3초가 걸렸다고 합니다. 3초면 인터넷이 심각하게 느린 위치에서 접속하는 사람이 아니라면 그냥 뒤로가기를 눌렀을 시간인데요. 원인은 **캐시 레이어 기기의 하드웨어 장애**였습니다. 문제는, 캐시 레이어 기기의 자동 Failover가 구성되어 있지 않아서 이슈 해결에 더 오랜 시간이 걸렸습니다. 

장애를 겪은 뒤, 캐시 설정에 고가용성을 더하고 캐시 장애가 발생했을 때 회복력(Resilience)이 있도록 캐시 레이어를 구성 해 비슷한 장애 상황에서도 요청 처리가 될 수 있도록 할 예정이라 합니다.

https://www.githubstatus.com/incidents/nm83zrdky73y  

## 2월

### 2월 25일

오후 11시 20분 경부터 새벽 1시 50분경 까지 2시간 30분동안 이메일 및 웹 알림에 장애가 있었습니다. 장애가 가장 심각했을 때는 ~10%의 알림이 전달되는데 10분이 넘고, 나머지 ~90%의 알림이 5~10분의 지연으로 전달되었습니다. **원인은 피크 시간대 사용량에 대응하지 못하는 워커 풀 용량**이었습니다. 추가로, 일부 웹훅이 최대 2.5분의 지연시간이 있었습니다. **해당 서비스를 스케일 아웃 해 장애를 해결**하였습니다.

이후, 가용량을 늘려 헤드룸을 넉넉하게 잡고 더 나은 가용량 계획을 할 수 있도록 작업을 진행할 예정입니다.

https://www.githubstatus.com/incidents/flt2rxl1dg1t

---

Status page 알림을 받고 있는데 생각보다 크고작은 장애가 많이 발생하더라구요. 그 링크를 타고 페이지로 들어가면 서비스별로 어떤 상태인지 이전 incident는 뭐가 있는지 상세하게 나와있는데요, 최근 장애 Post Mortem/회고 글과 영상을 재미있게 보고 있어 흥미가 갔습니다. 장애 발생 시 일단 상황들을 공유하고, 이후 장애 해결되면 원인과 어떤 해결책을 사용했는지 및 앞으로 어떻게 대응할건지 잘 정리가 되어 있어 간접 경험이 쌓이는 것 같아요. 재미있는 Post Mortem 글 있으면 더 자세하게 정리해서 포스팅 해보면 좋을 것 같습니다.